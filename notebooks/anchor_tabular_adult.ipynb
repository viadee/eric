{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anchor explanations for income prediction\n",
    "\n",
    "In this example, we will explain predictions of a Random Forest classifier whether a person will make more or less than $50k based on characteristics like age, marital status, gender or occupation. The features are a mixture of ordinal and categorical data and will be pre-processed accordingly."
   ]
  },
  {
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi.datasets import fetch_adult"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_adult` function returns a `Bunch` object containing the features, the targets, the feature names and a mapping of categorical variables to numbers which are required for formatting the output of the Anchor explainer."
   ]
  },
  {
   "source": [
    "adult = fetch_adult()\n",
    "adult.keys()"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['data', 'target', 'feature_names', 'target_names', 'category_map'])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "source": [
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 6
  },
  {
   "source": [
    "print(feature_names)\n",
    "print(category_map)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Age', 'Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Country']\n{1: ['?', 'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], 2: ['Associates', 'Bachelors', 'Doctorate', 'Dropout', 'High School grad', 'Masters', 'Prof-School'], 3: ['Married', 'Never-Married', 'Separated', 'Widowed'], 4: ['?', 'Admin', 'Blue-Collar', 'Military', 'Other', 'Professional', 'Sales', 'Service', 'White-Collar'], 5: ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], 6: ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], 7: ['Female', 'Male'], 11: ['?', 'British-Commonwealth', 'China', 'Euro_1', 'Euro_2', 'Latin-America', 'Other', 'SE-Asia', 'South-America', 'United-States', 'Yugoslavia']}\n"
    }
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for your own datasets you can use our utility function [gen_category_map](../api/alibi.utils.data.rst) to create the category map:"
   ]
  },
  {
   "source": [
    "from alibi.utils.data import gen_category_map"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define shuffled training and test set"
   ]
  },
  {
   "source": [
    "np.random.seed(0)\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "data = data_perm[:,:-1]\n",
    "target = data_perm[:,-1]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 9
  },
  {
   "source": [
    "idx = 30000\n",
    "X_train,Y_train = data[:idx,:], target[:idx]\n",
    "X_test, Y_test = data[idx+1:,:], target[idx+1:]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature transformation pipeline\n",
    "Create feature pre-processor. Needs to have 'fit' and 'transform' methods. Different types of pre-processing can be applied to all or part of the features. In the example below we will standardize ordinal features and apply one-hot-encoding to categorical features.\n",
    "\n",
    "Ordinal features:"
   ]
  },
  {
   "source": [
    "ordinal_features = [x for x in range(len(feature_names)) if x not in list(category_map.keys())]\n",
    "ordinal_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical features:"
   ]
  },
  {
   "source": [
    "categorical_features = list(category_map.keys())\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and fit:"
   ]
  },
  {
   "source": [
    "preprocessor = ColumnTransformer(transformers=[('num', ordinal_transformer, ordinal_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)])\n",
    "preprocessor.fit(X_train)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n                  transformer_weights=None,\n                  transformers=[('num',\n                                 Pipeline(memory=None,\n                                          steps=[('imputer',\n                                                  SimpleImputer(add_indicator=False,\n                                                                copy=True,\n                                                                fill_value=None,\n                                                                missing_values=nan,\n                                                                strategy='median',\n                                                                verbose=0)),\n                                                 ('scaler',\n                                                  StandardScaler(copy=True,\n                                                                 with_mean=True,\n                                                                 with_std=True))],\n                                          verbose=False),\n                                 [0, 8, 9...\n                                 Pipeline(memory=None,\n                                          steps=[('imputer',\n                                                  SimpleImputer(add_indicator=False,\n                                                                copy=True,\n                                                                fill_value=None,\n                                                                missing_values=nan,\n                                                                strategy='median',\n                                                                verbose=0)),\n                                                 ('onehot',\n                                                  OneHotEncoder(categorical_features=None,\n                                                                categories=None,\n                                                                drop=None,\n                                                                dtype=<class 'numpy.float64'>,\n                                                                handle_unknown='ignore',\n                                                                n_values=None,\n                                                                sparse=True))],\n                                          verbose=False),\n                                 [1, 2, 3, 4, 5, 6, 7, 11])],\n                  verbose=False)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Random Forest model\n",
    "\n",
    "Fit on pre-processed (imputing, OHE, standardizing) data."
   ]
  },
  {
   "source": [
    "np.random.seed(0)\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(preprocessor.transform(X_train), Y_train)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=50,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define predict function"
   ]
  },
  {
   "source": [
    "predict_fn = lambda x: clf.predict(preprocessor.transform(x))\n",
    "print('Train accuracy: ', accuracy_score(Y_train, predict_fn(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(Y_test, predict_fn(X_test)))"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train accuracy:  0.9655333333333334\nTest accuracy:  0.855859375\n"
    }
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "source": [
    "print(predict_fn([X_test[0]]))"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0]\n"
    }
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and fit anchor explainer for tabular data"
   ]
  },
  {
   "source": [
    "print(X_test[0])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[52  4  0  2  8  4  2  0  0  0 60  9]\n"
    }
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "source": [
    "print(category_map)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{1: ['?', 'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], 2: ['Associates', 'Bachelors', 'Doctorate', 'Dropout', 'High School grad', 'Masters', 'Prof-School'], 3: ['Married', 'Never-Married', 'Separated', 'Widowed'], 4: ['?', 'Admin', 'Blue-Collar', 'Military', 'Other', 'Professional', 'Sales', 'Service', 'White-Collar'], 5: ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], 6: ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], 7: ['Female', 'Male'], 11: ['?', 'British-Commonwealth', 'China', 'Euro_1', 'Euro_2', 'Latin-America', 'Other', 'SE-Asia', 'South-America', 'United-States', 'Yugoslavia']}\n"
    }
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "source": [
    "print(feature_names)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Age', 'Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Country']\n"
    }
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "source": [
    "explainer = AnchorTabular(predict_fn, feature_names, categorical_names=category_map)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize the ordinal features into quartiles"
   ]
  },
  {
   "source": [
    "explainer.fit(X_train, disc_perc=[25, 50, 75])"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an anchor\n",
    "\n",
    "Below, we get an anchor for the prediction of the first observation in the test set. An anchor is a sufficient condition - that is, when the anchor holds, the prediction should be the same as the prediction for this instance."
   ]
  },
  {
   "source": [
    "idx = 0\n",
    "class_names = adult.target_names\n",
    "print('Prediction: ', class_names[explainer.predict_fn(X_test[idx].reshape(1, -1))[0]])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction:  <=50K\n"
    }
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the precision threshold to 0.95. This means that predictions on observations where the anchor holds will be the same as the prediction on the explained instance at least 95% of the time."
   ]
  },
  {
   "source": [
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation['names'])))\n",
    "print('Precision: %.2f' % explanation['precision'])\n",
    "print('Coverage: %.2f' % explanation['coverage'])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Anchor: Marital Status = Separated AND Sex = Female\nPrecision: 0.96\nCoverage: 0.11\n"
    }
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "source": [
    "print(explanation)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'names': ['Marital Status = Separated', 'Sex = Female'], 'precision': 0.9576470588235294, 'coverage': 0.1054, 'raw': {'feature': [3, 7], 'mean': [0.8934221482098251, 0.9576470588235294], 'precision': [0.8934221482098251, 0.9576470588235294], 'coverage': [0.176, 0.1054], 'examples': [{'covered': array([[   44,     1,     0,     2,     2,     0,     4,     1,     0,\n            0,    40,     9],\n       [   37,     4,     4,     2,     6,     4,     4,     0,     0,\n            0,    40,     9],\n       [   20,     2,     4,     2,     4,     0,     2,     1,     0,\n            0,    30,     5],\n       [   37,     4,     3,     2,     2,     1,     4,     1,     0,\n            0,    65,     9],\n       [   66,     5,     1,     2,     8,     0,     4,     1, 10605,\n            0,    40,     9],\n       [   49,     4,     4,     2,     2,     1,     4,     1,     0,\n            0,    40,     9],\n       [   52,     4,     3,     2,     2,     0,     4,     1,     0,\n            0,    40,     9],\n       [   49,     4,     0,     2,     2,     0,     4,     1,     0,\n            0,    45,     4],\n       [   51,     4,     4,     2,     2,     4,     4,     0,     0,\n            0,    40,     9],\n       [   21,     4,     3,     2,     2,     0,     4,     1,     0,\n            0,    40,     5]]), 'covered_true': array([[  66,    0,    4,    2,    0,    0,    4,    1,    0,    0,   30,\n           9],\n       [  23,    4,    1,    2,    4,    1,    2,    0,    0,    0,   45,\n           9],\n       [  30,    4,    0,    2,    1,    2,    1,    1, 2463,    0,   40,\n           7],\n       [  25,    4,    3,    2,    2,    0,    4,    1,    0,    0,   40,\n           9],\n       [  49,    4,    4,    2,    2,    4,    4,    1,    0,    0,   40,\n           9],\n       [  44,    4,    4,    2,    2,    0,    4,    1,    0,    0,   40,\n           9],\n       [  51,    4,    3,    2,    6,    0,    4,    1, 4386,    0,   30,\n           9],\n       [  44,    4,    4,    2,    8,    1,    4,    0,    0,    0,   50,\n           9],\n       [  41,    4,    4,    2,    2,    0,    4,    1,    0,    0,   40,\n           9],\n       [  51,    4,    4,    2,    2,    0,    4,    1,    0,    0,   40,\n           9]]), 'covered_false': array([[   39,     4,     5,     2,     8,     0,     1,     1, 15024,\n            0,    40,     9],\n       [   56,     2,     5,     2,     8,     0,     2,     1,     0,\n            0,    40,     9],\n       [   49,     1,     5,     2,     1,     0,     4,     1,     0,\n            0,    40,     9],\n       [   53,     4,     5,     2,     5,     0,     4,     1,     0,\n            0,    40,     9],\n       [   39,     1,     6,     2,     5,     1,     4,     1,     0,\n            0,    55,     9],\n       [   34,     4,     1,     2,     8,     0,     4,     1, 15024,\n            0,    60,     9],\n       [   35,     4,     1,     2,     5,     0,     4,     1,     0,\n            0,    45,     9],\n       [   32,     4,     6,     2,     5,     0,     4,     1,     0,\n            0,    40,     9],\n       [   39,     2,     1,     2,     5,     0,     4,     1,     0,\n         1887,    40,     9],\n       [   48,     4,     5,     2,     2,     0,     4,     1,     0,\n            0,    55,     9]]), 'uncovered_true': array([], dtype=float64), 'uncovered_false': array([], dtype=float64)}, {'covered': array([[  35,    4,    4,    2,    1,    1,    4,    0,    0,    0,   40,\n           9],\n       [  38,    6,    1,    2,    6,    5,    4,    0,    0,    0,   60,\n           9],\n       [  19,    0,    4,    2,    0,    3,    4,    0,    0,    0,   15,\n           9],\n       [  40,    4,    6,    2,    8,    1,    4,    0,    0,    0,   40,\n           6],\n       [  17,    0,    3,    2,    0,    3,    3,    0,    0,    0,   20,\n           9],\n       [  70,    0,    4,    2,    0,    1,    4,    0, 2009,    0,   40,\n           9],\n       [  20,    4,    3,    2,    2,    3,    4,    0,    0,    0,   11,\n           5],\n       [  19,    5,    4,    2,    7,    3,    1,    0,    0,    0,   35,\n           4],\n       [  19,    4,    4,    2,    2,    3,    4,    0,    0,    0,   40,\n           9],\n       [  20,    4,    4,    2,    6,    3,    4,    0,    0,    0,   30,\n           9]]), 'covered_true': array([[  21,    0,    4,    2,    0,    3,    4,    0,    0,    0,   35,\n           9],\n       [  33,    4,    1,    2,    7,    5,    4,    0,    0,    0,   40,\n           9],\n       [  38,    4,    4,    2,    5,    4,    4,    0,    0,    0,   40,\n           3],\n       [  31,    4,    4,    2,    2,    3,    4,    0,    0,    0,   40,\n           9],\n       [  72,    1,    3,    2,    1,    1,    4,    0,    0,    0,    8,\n           1],\n       [  21,    4,    4,    2,    6,    3,    4,    0,    0,    0,    8,\n           9],\n       [  25,    4,    0,    2,    4,    3,    4,    0,    0, 1594,   25,\n           9],\n       [  72,    4,    3,    2,    1,    4,    4,    0,    0,    0,   40,\n           9],\n       [  46,    4,    3,    2,    5,    5,    4,    0,    0,    0,   45,\n           9],\n       [  25,    4,    1,    2,    8,    3,    4,    0,    0,    0,   20,\n           9]]), 'covered_false': array([[   43,     4,     5,     2,     8,     1,     4,     0,     0,\n            0,    50,     9],\n       [   28,     2,     5,     2,     5,     5,     4,     0,  7298,\n            0,    40,     9],\n       [   39,     4,     6,     2,     8,     5,     4,     0, 15024,\n            0,    47,     9],\n       [   33,     1,     6,     2,     5,     1,     4,     0,     0,\n            0,    65,     9],\n       [   55,     4,     5,     2,     5,     1,     4,     0, 14084,\n            0,    40,     9],\n       [   48,     1,     1,     2,     1,     5,     4,     0,  7688,\n            0,    40,     9],\n       [   67,     2,     5,     2,     8,     2,     4,     0, 15831,\n            0,    72,     9],\n       [   36,     4,     5,     2,     8,     1,     4,     0, 14084,\n            0,    40,     9],\n       [   51,     4,     4,     2,     1,     4,     4,     0,     0,\n         2547,    40,     9],\n       [   49,     4,     1,     2,     5,     5,     4,     0, 99999,\n            0,    20,     9]]), 'uncovered_true': array([], dtype=float64), 'uncovered_false': array([], dtype=float64)}], 'all_precision': 0, 'num_preds': 1000001, 'names': ['Marital Status = Separated', 'Sex = Female'], 'instance': array([52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60,  9]), 'prediction': 0}, 'meta': {'name': 'AnchorTabular'}}\n"
    }
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...or not?\n",
    "\n",
    "Let's try getting an anchor for a different observation in the test set - one for the which the prediction is `>50K`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  >50K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an anchor satisfying the 0.95 precision constraint. Now returning the best non-eligible anchor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Capital Loss > 0.00 AND Marital Status = Married AND Relationship = Husband AND Age > 47.00 AND Race = White AND Sex = Male AND Country = United-States AND Workclass = Self-emp-not-inc AND Capital Gain <= 0.00\n",
      "Precision: 0.64\n",
      "Coverage: 0.00\n"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "class_names = adult.target_names\n",
    "print('Prediction: ', class_names[explainer.predict_fn(X_test[idx].reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation['names'])))\n",
    "print('Precision: %.2f' % explanation['precision'])\n",
    "print('Coverage: %.2f' % explanation['coverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how no anchor is found!\n",
    "\n",
    "This is due to the imbalanced dataset (roughly 25:75 high:low earner proportion), so during the sampling stage feature ranges corresponding to low-earners will be oversampled. This is a feature because it can point out an imbalanced dataset, but it can also be fixed by producing balanced datasets to enable anchors to be found for either class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}