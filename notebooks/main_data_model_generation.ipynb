{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# import DiCE\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import dice_ml\n","from dice_ml.utils import helpers \n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","data = pd.read_csv('titanic.csv')\n","data.rename(columns={'Survived': 'class'}, inplace=True)\n","data['Sex'] = data['Sex'].map({'male':'Male','female':'Female'})\n","data['Embarked'] = data['Embarked'].map({'S':'Southampton','C':'Cherbourg','Q':'Queenstown'})\n","data['Pclass'] = data['Pclass'].map({1:'First',2:'Second',3:'Third'})\n","#data = data.fillna(-999)\n","\n","data['Relatives'] = data['SibSp'] + data['Parch']\n","\n","data = data.drop(['PassengerId', 'Name','Ticket','Cabin', 'SibSp', 'Parch'], axis=1)\n","data = data.dropna()\n","\n","train_df, test_df = train_test_split(\n","            data, test_size=0.2, random_state=17)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#data.to_csv(\"titanic_full.csv\")\n","train_df.to_csv(\"titanic_train.csv\", index=False)\n","test_df.to_csv(\"titanic_test.csv\", index=False)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"class  Pclass     Sex   Age      Fare     Embarked  Relatives\n377      0   First    Male  27.0  211.5000    Cherbourg          2\n88       1   First  Female  23.0  263.0000  Southampton          5\n296      0   Third    Male  23.5    7.2292    Cherbourg          0\n389      1  Second  Female  17.0   12.0000    Cherbourg          0\n708      1   First  Female  22.0  151.5500  Southampton          0\n..     ...     ...     ...   ...       ...          ...        ...\n512      1   First    Male  36.0   26.2875  Southampton          0\n491      0   Third    Male  21.0    7.2500  Southampton          0\n179      0   Third    Male  36.0    0.0000  Southampton          0\n302      0   Third    Male  19.0    0.0000  Southampton          0\n784      0   Third    Male  25.0    7.0500  Southampton          0\n\n[569 rows x 7 columns]\n"}],"source":["print(train_df)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'train_pre' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-55176db9c57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_pre' is not defined"]}],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train_pre = pd.get_dummies(train_df, drop_first=False, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n","\n","result1 = train_pre.copy()\n","for feature_name in ['Age', 'Fare', 'Relatives']:\n","    max_value = data[feature_name].max()\n","    min_value = data[feature_name].min()\n","    result1[feature_name] = (\n","        train_pre[feature_name] - min_value) / (max_value - min_value)\n","train_pre = result1\n","\n","test_pre = pd.get_dummies(test_df, drop_first=False, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n","\n","result2 = test_pre.copy()\n","for feature_name in ['Age', 'Fare', 'Relatives']:\n","    max_value = data[feature_name].max()\n","    min_value = data[feature_name].min()\n","    result2[feature_name] = (\n","        test_pre[feature_name] - min_value) / (max_value - min_value)\n","test_pre = result2\n","#print(train_pre)\n","\n","X_train = train_pre.loc[:, train_pre.columns != 'class']\n","y_train = train_pre.loc[:, train_pre.columns == 'class']\n","X_test = test_pre.loc[:, test_pre.columns != 'class']\n","y_test = test_pre.loc[:, train_pre.columns == 'class']\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x144012a20>"},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["sess = tf.InteractiveSession()\n","\n","ann_model = keras.Sequential()\n","ann_model.add(keras.layers.Dense(20, input_shape=(X_train.shape[1],), kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu))\n","ann_model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n","ann_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.01), metrics=['accuracy'])\n","ann_model.fit(X_train, y_train, validation_split=0.20, epochs=100, verbose=0)\n","\n","#sess = tf.InteractiveSession()\n","\n","#ann_model = keras.Sequential()\n","#ann_model.add(keras.layers.Dense(20, input_shape=(X_train.shape[1],), kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu))\n","#ann_model.add(keras.layers.Dense(2, activation=tf.nn.sigmoid))\n","#ann_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.01), metrics=['accuracy'])\n","#ann_model.fit(X_train, to_categorical(y_train), validation_split=0.20, epochs=100, verbose=0)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.8041958\n"}],"source":["#print(ann_model.evaluate(X_test, to_categorical(y_test), verbose=0)[1])\n","#print(ann_model.predict(X_test.head(1)))\n","print(ann_model.evaluate(X_test, y_test, verbose=0)[1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["ann_model.save('titanic_ann.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.2"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}