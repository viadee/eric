{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual explanations with ordinally encoded categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook illustrates how to obtain [counterfactual explanations](../doc/source/methods/CFProto.ipynb) for instances with a mixture of ordinally encoded categorical and numerical variables. A more elaborate notebook highlighting additional functionality can be found [here](./cfproto_cat_adult_ohe.ipynb). We generate counterfactuals for instances in the *adult* dataset where we predict whether a person's income is above or below $50k."
   ]
  },
  {
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # suppress deprecation messages\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Concatenate, Reshape, Dropout, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import time\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.explainers import CounterFactualProto"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_adult` function returns a `Bunch` object containing the features, the targets, the feature names and a mapping of the categories in each categorical variable."
   ]
  },
  {
   "source": [
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map_tmp = adult.category_map\n",
    "target_names = adult.target_names\n",
    "print(feature_names)\n",
    "print(category_map_tmp)\n",
    "print(data)\n",
    "print(target_names)\n",
    "print(target[1])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Age', 'Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Country']\n{1: ['?', 'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], 2: ['Associates', 'Bachelors', 'Doctorate', 'Dropout', 'High School grad', 'Masters', 'Prof-School'], 3: ['Married', 'Never-Married', 'Separated', 'Widowed'], 4: ['?', 'Admin', 'Blue-Collar', 'Military', 'Other', 'Professional', 'Sales', 'Service', 'White-Collar'], 5: ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], 6: ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], 7: ['Female', 'Male'], 11: ['?', 'British-Commonwealth', 'China', 'Euro_1', 'Euro_2', 'Latin-America', 'Other', 'SE-Asia', 'South-America', 'United-States', 'Yugoslavia']}\n[[39  7  1 ...  0 40  9]\n [50  6  1 ...  0 13  9]\n [38  4  4 ...  0 40  9]\n ...\n [58  4  4 ...  0 40  9]\n [22  4  4 ...  0 20  9]\n [52  5  4 ...  0 40  9]]\n['<=50K', '>50K']\n0\n"
    }
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define shuffled training and test set:"
   ]
  },
  {
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.set_random_seed(s)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 5
  },
  {
   "source": [
    "set_seed()\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "X = data_perm[:,:-1]\n",
    "y = data_perm[:,-1]\n",
    "print(X)\n",
    "print(y)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[27  4  4 ...  0 44  9]\n [27  4  1 ...  0 40  9]\n [25  4  0 ...  0 40  9]\n ...\n [23  4  4 ...  0 40  9]\n [45  2  2 ...  0 45  9]\n [25  4  4 ...  0 48  9]]\n[0 0 0 ... 0 1 0]\n"
    }
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "source": [
    "idx = 30000\n",
    "y_train, y_test = y[:idx], y[idx+1:]\n",
    "print(y_train)\n",
    "print(y_test)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 0 0 ... 0 0 0]\n[0 0 0 ... 0 1 0]\n"
    }
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganize data so categorical features come first:"
   ]
  },
  {
   "source": [
    "X = np.c_[X[:, 1:8], X[:, 11], X[:, 0], X[:, 8:11]]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `feature_names` and `category_map` as well:"
   ]
  },
  {
   "source": [
    "feature_names = feature_names[1:8] + feature_names[11:12] + feature_names[0:1] + feature_names[8:11]\n",
    "print(feature_names)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Workclass', 'Education', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country', 'Age', 'Capital Gain', 'Capital Loss', 'Hours per week']\n"
    }
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "source": [
    "category_map = {}\n",
    "for i, (_, v) in enumerate(category_map_tmp.items()):\n",
    "    category_map[i] = v\n",
    "\n",
    "print(category_map)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{0: ['?', 'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], 1: ['Associates', 'Bachelors', 'Doctorate', 'Dropout', 'High School grad', 'Masters', 'Prof-School'], 2: ['Married', 'Never-Married', 'Separated', 'Widowed'], 3: ['?', 'Admin', 'Blue-Collar', 'Military', 'Other', 'Professional', 'Sales', 'Service', 'White-Collar'], 4: ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], 5: ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], 6: ['Female', 'Male'], 7: ['?', 'British-Commonwealth', 'China', 'Euro_1', 'Euro_2', 'Latin-America', 'Other', 'SE-Asia', 'South-America', 'United-States', 'Yugoslavia']}\n"
    }
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with as keys the categorical columns and values the number of categories for each variable in the dataset. This dictionary will later be used in the counterfactual explanation."
   ]
  },
  {
   "source": [
    "cat_vars_ord = {}\n",
    "n_categories = len(list(category_map.keys()))\n",
    "for i in range(n_categories):\n",
    "    cat_vars_ord[i] = len(np.unique(X[:, i]))\n",
    "print(cat_vars_ord)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{0: 9, 1: 7, 2: 4, 3: 9, 4: 6, 5: 5, 6: 2, 7: 11}\n"
    }
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale numerical features between -1 and 1:"
   ]
  },
  {
   "source": [
    "X_num = X[:, -4:].astype(np.float32, copy=False)\n",
    "xmin, xmax = X_num.min(axis=0), X_num.max(axis=0)\n",
    "rng = (-1., 1.)\n",
    "X_num_scaled = (X_num - xmin) / (xmax - xmin) * (rng[1] - rng[0]) + rng[0]\n",
    "X_num_scaled_train = X_num_scaled[:idx, :]\n",
    "X_num_scaled_test = X_num_scaled[idx+1:, :]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine numerical and categorical data:"
   ]
  },
  {
   "source": [
    "X = np.c_[X[:, :-4], X_num_scaled].astype(np.float32, copy=False)\n",
    "X_train, X_test = X[:idx, :], X[idx+1:, :]\n",
    "print(X_train.shape, X_test.shape)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(30000, 12) (2560, 12)\n"
    }
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net will use entity embeddings for the categorical variables."
   ]
  },
  {
   "source": [
    "print(X_train)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 4.          4.          2.         ... -1.         -1.\n  -0.12244898]\n [ 4.          1.          1.         ... -1.         -1.\n  -0.20408165]\n [ 4.          0.          0.         ... -1.         -1.\n  -0.20408165]\n ...\n [ 4.          4.          1.         ... -1.         -1.\n  -0.20408165]\n [ 4.          4.          0.         ... -0.92183924 -1.\n  -0.20408165]\n [ 4.          3.          0.         ... -1.         -1.\n  -0.6122449 ]]\n"
    }
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_ord():\n",
    "    \n",
    "    x_in = Input(shape=(12,))\n",
    "    layers_in = []\n",
    "    \n",
    "    # embedding layers\n",
    "    for i, (_, v) in enumerate(cat_vars_ord.items()):\n",
    "        emb_in = Lambda(lambda x: x[:, i:i+1])(x_in)\n",
    "        emb_dim = int(max(min(np.ceil(.5 * v), 50), 2))\n",
    "        emb_layer = Embedding(input_dim=v+1, output_dim=emb_dim, input_length=1)(emb_in)\n",
    "        emb_layer = Reshape(target_shape=(emb_dim,))(emb_layer)\n",
    "        layers_in.append(emb_layer)\n",
    "        \n",
    "    # numerical layers\n",
    "    num_in = Lambda(lambda x: x[:, -4:])(x_in)\n",
    "    num_layer = Dense(16)(num_in)\n",
    "    layers_in.append(num_layer)\n",
    "    \n",
    "    # combine\n",
    "    x = Concatenate()(layers_in)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(60, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x_out = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    nn = Model(inputs=x_in, outputs=x_out)\n",
    "    nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 12)           0                                            \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_4 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_5 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_6 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nlambda_7 (Lambda)               (None, 1)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 1, 5)         50          lambda[0][0]                     \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 4)         32          lambda_1[0][0]                   \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 2)         10          lambda_2[0][0]                   \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 5)         50          lambda_3[0][0]                   \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         21          lambda_4[0][0]                   \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 3)         18          lambda_5[0][0]                   \n__________________________________________________________________________________________________\nembedding_6 (Embedding)         (None, 1, 2)         6           lambda_6[0][0]                   \n__________________________________________________________________________________________________\nembedding_7 (Embedding)         (None, 1, 6)         72          lambda_7[0][0]                   \n__________________________________________________________________________________________________\nlambda_8 (Lambda)               (None, 4)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\nreshape (Reshape)               (None, 5)            0           embedding[0][0]                  \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 4)            0           embedding_1[0][0]                \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 2)            0           embedding_2[0][0]                \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 5)            0           embedding_3[0][0]                \n__________________________________________________________________________________________________\nreshape_4 (Reshape)             (None, 3)            0           embedding_4[0][0]                \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 3)            0           embedding_5[0][0]                \n__________________________________________________________________________________________________\nreshape_6 (Reshape)             (None, 2)            0           embedding_6[0][0]                \n__________________________________________________________________________________________________\nreshape_7 (Reshape)             (None, 6)            0           embedding_7[0][0]                \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 16)           80          lambda_8[0][0]                   \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 46)           0           reshape[0][0]                    \n                                                                 reshape_1[0][0]                  \n                                                                 reshape_2[0][0]                  \n                                                                 reshape_3[0][0]                  \n                                                                 reshape_4[0][0]                  \n                                                                 reshape_5[0][0]                  \n                                                                 reshape_6[0][0]                  \n                                                                 reshape_7[0][0]                  \n                                                                 dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 60)           2820        concatenate[0][0]                \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 60)           0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 60)           3660        dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 60)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 60)           3660        dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 60)           0           dense_3[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 2)            122         dropout_2[0][0]                  \n==================================================================================================\nTotal params: 10,601\nTrainable params: 10,601\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x13d85f400>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "nn = nn_ord()\n",
    "nn.summary()\n",
    "nn.fit(X_train, to_categorical(y_train), batch_size=128, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate counterfactual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 4.          0.          2.          8.          4.          2.\n   0.          9.         -0.04109591 -1.         -1.          0.20408165]]\n"
    }
   ],
   "source": [
    "X = X_test[0].reshape((1,) + X_test[0].shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize counterfactual parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(array([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]],\n      dtype=float32), array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32))\n(1, 12)\n"
    }
   ],
   "source": [
    "shape = X.shape\n",
    "beta = .01\n",
    "c_init = 1.\n",
    "c_steps = 5\n",
    "max_iterations = 500\n",
    "rng = (-1., 1.)  # scale features between -1 and 1\n",
    "rng_shape = (1,) + data.shape[1:]\n",
    "feature_range = ((np.ones(rng_shape) * rng[0]).astype(np.float32), \n",
    "                 (np.ones(rng_shape) * rng[1]).astype(np.float32))\n",
    "print(feature_range)\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize explainer. Since the `Embedding` layers in `tf.keras` do not let gradients propagate through, we will only make use of the model's predict function, treat it as a black box and perform numerical gradient calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "# define predict function\n",
    "predict_fn = lambda x: nn.predict(x)\n",
    "\n",
    "cf = CounterFactualProto(predict_fn,\n",
    "                         shape,\n",
    "                         beta=beta,\n",
    "                         cat_vars=cat_vars_ord,\n",
    "                         max_iterations=max_iterations,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=c_init,\n",
    "                         c_steps=c_steps,\n",
    "                         eps=(1e-2, 1e-2)  # perturbation size for numerical gradients\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit explainer. Please check the [documentation](../doc/source/methods/CFProto.ipynb) for more info about the optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.fit(X_train, d_type='abdm', disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "explanation = cf.explain(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to more clearly describe explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_instance(X, explanation, eps=1e-2):\n",
    "    print('Original instance: {}  -- proba: {}'.format(target_names[explanation['orig_class']],\n",
    "                                                       explanation['orig_proba'][0]))\n",
    "    print('Counterfactual instance: {}  -- proba: {}'.format(target_names[explanation['cf']['class']],\n",
    "                                                             explanation['cf']['proba'][0]))\n",
    "    print('\\nCounterfactual perturbations...')\n",
    "    print('\\nCategorical:')\n",
    "    X_orig_ord = X\n",
    "    X_cf_ord = explanation['cf']['X']\n",
    "    delta_cat = {}\n",
    "    for i, (_, v) in enumerate(category_map.items()):\n",
    "        cat_orig = v[int(X_orig_ord[0, i])]\n",
    "        cat_cf = v[int(X_cf_ord[0, i])]\n",
    "        if cat_orig != cat_cf:\n",
    "            delta_cat[feature_names[i]] = [cat_orig, cat_cf]\n",
    "    if delta_cat:\n",
    "        for k, v in delta_cat.items():\n",
    "            print('{}: {}  -->   {}'.format(k, v[0], v[1]))\n",
    "    print('\\nNumerical:')\n",
    "    delta_num = X_cf_ord[0, -4:] - X_orig_ord[0, -4:]\n",
    "    n_keys = len(list(cat_vars_ord.keys()))\n",
    "    for i in range(delta_num.shape[0]):\n",
    "        if np.abs(delta_num[i]) > eps:\n",
    "            print('{}: {:.2f}  -->   {:.2f}'.format(feature_names[i+n_keys],\n",
    "                                            X_orig_ord[0,i+n_keys],\n",
    "                                            X_cf_ord[0,i+n_keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Original instance: <=50K  -- proba: [0.80113995 0.19886011]\nCounterfactual instance: >50K  -- proba: [0.35201833 0.64798164]\n\nCounterfactual perturbations...\n\nCategorical:\nCountry: United-States  -->   Latin-America\n\nNumerical:\nCapital Gain: -1.00  -->   -0.87\n"
    }
   ],
   "source": [
    "describe_instance(X, explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The person's incomce is predicted to be above $50k by increasing his or her capital gain and changing occupation to *Professional*."
   ]
  },
  {
   "source": [
    "print(X_test[0].reshape((1,12)))\n",
    "#print(explanation)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 4.          0.          2.          8.          4.          2.\n   0.          9.         -0.04109591 -1.         -1.          0.20408165]]\n"
    }
   ],
   "metadata": {},
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 4.          1.          1.          5.          1.          4.\n  0.          9.         -0.72602737 -1.         -1.         -0.20408165]\n"
    }
   ],
   "source": [
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}