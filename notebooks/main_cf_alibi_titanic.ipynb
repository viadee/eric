{
 "cells": [
  {
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import time\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.explainers import CounterFactualProto\n",
    "import pandas as pd \n",
    "from mlobject import *\n",
    "import tensorflow as tf\n",
    "from alibi.explainers import CounterFactual\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 1
  },
  {
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "data.rename(columns={'Survived': 'class'}, inplace=True)\n",
    "data['Sex'] = data['Sex'].map({'male':0,'female':1})\n",
    "data['Embarked'] = data['Embarked'].map({'S':0,'C':1,'Q':2})\n",
    "data['Relatives'] = data['SibSp'] + data['Parch']\n",
    "\n",
    "data = data.drop(['PassengerId', 'Name','Ticket','Cabin', 'SibSp', 'Parch'], axis=1)\n",
    "data = data.dropna()\n",
    "\n",
    "f = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Relatives']\n",
    "\n",
    "features = data.drop('class', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "    train_test_split(features, data['class'].values, random_state=None)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 10
  },
  {
   "source": [
    "train_df = pd.read_csv(\"titanic_train.csv\")\n",
    "train_df['Sex'] = train_df['Sex'].map({'Male':0,'Female':1})\n",
    "train_df['Pclass'] = train_df['Pclass'].map({'First':0,'Second':1,'Third':2})\n",
    "train_df['Embarked'] = train_df['Embarked'].map({'Southampton':0,'Cherbourg':1,'Queenstown':2})\n",
    "#train_df = train_df.to_numpy()\n",
    "\n",
    "test_df = pd.read_csv(\"titanic_test.csv\")\n",
    "test_df['Sex'] = test_df['Sex'].map({'Male':0,'Female':1})\n",
    "test_df['Pclass'] = test_df['Pclass'].map({'First':1,'Second':2,'Third':3})\n",
    "test_df['Embarked'] = test_df['Embarked'].map({'Southampton':0,'Cherbourg':1,'Queenstown':2})\n",
    "#test_df = test_df.to_numpy()\n",
    "\n",
    "X_train = train_df.loc[:, train_df.columns != 'class'].to_numpy()\n",
    "y_train = train_df.loc[:, train_df.columns == 'class'].to_numpy()\n",
    "X_test = test_df.loc[:, test_df.columns != 'class'].to_numpy()\n",
    "y_test = test_df.loc[:, test_df.columns == 'class'].to_numpy()"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[  1.       1.      18.     262.375    1.       4.    ]\n [  3.       1.      14.      11.2417   1.       1.    ]\n [  3.       0.       4.      11.1333   0.       2.    ]\n ...\n [  3.       0.      28.5     16.1      0.       0.    ]\n [  3.       0.      44.       8.05     0.       0.    ]\n [  3.       1.      22.       7.75     2.       0.    ]]\n"
    }
   ],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "source": [
    "model = svm.SVC(gamma=0.001, C=100., probability=True)\n",
    "    \n",
    "model.fit(training_features, training_target)\n",
    "certainty = metrics.accuracy_score(testing_target, model.predict(testing_features))\n",
    "print(\"Accuracy:\", certainty)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.7696629213483146\n"
    }
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "source": [
    "print(np.array([3, 0, 32, 10.0, 0, 0]))\n",
    "print(model.predict_proba([np.array([1, 0, 60, 50, 0, 0])]))"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 3.  0. 32. 10.  0.  0.]\n[[0.80761428 0.19238572]]\n"
    }
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "source": [
    "predict_fn = lambda x: model.predict_proba(x)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 8
  },
  {
   "source": [
    "shape = (1,) + X_train.shape[1:]\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CounterFactual(predict_fn, (1,6), distance_fn='l1', target_proba=0.6,\n",
    "                    target_class='other', max_iter=1000, early_stop=50, lam_init=1e-1,\n",
    "                    max_lam_steps=10, tol=0.05, learning_rate_init=0.1,\n",
    "                    feature_range= (np.array([2, 0, 100, 100, 2, 4]), np.array([2, 1, 100, 100, 2, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = cf.explain(np.array([2, 0, 32, 20.0, 0, 0], ndmin=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'X': array([[ 1.9992642 ,  0.55875885, 32.0012    , 20.002869  ,  0.        ,\n         0.        ]], dtype=float32), 'distance': 0.5635648965835571, 'lambda': 0.055, 'index': 65, 'class': 1, 'proba': array([[0.44821809, 0.55178191]]), 'loss': 0.03332105363612798}\n"
    }
   ],
   "source": [
    "print(explanation['cf'])"
   ]
  },
  {
   "source": [
    "cf = CounterFactualProto(predict_fn,\n",
    "                         shape,\n",
    "                         beta=0.1,\n",
    "                         cat_vars={0:3, 1:2, 4:3},\n",
    "                         #cat_vars={0:3, 1:2, 4:3},\n",
    "                         max_iterations=1000,\n",
    "                         feature_range= (np.array([[1, 0, 0, 0, 0, 0]]), np.array([[3, 1, 90, 600, 2, 10]])),\n",
    "                         #feature_range= (np.array([[-1, -1, -1, -1, -1, -1]]), np.array([[1, 1, 1, 1, 1, 1]])),\n",
    "                         c_init=1.,\n",
    "                         c_steps=5,\n",
    "                         eps=(.01, .01)  # perturbation size for numerical gradients\n",
    "                        )"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/christianwerner/anaconda3/envs/masterthesis/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /Users/christianwerner/anaconda3/envs/masterthesis/lib/python3.7/site-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nWARNING:tensorflow:From /Users/christianwerner/anaconda3/envs/masterthesis/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
    }
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "source": [
    "cf.fit(training_features, d_type='abdm', disc_perc=[25, 50, 75])"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 12
  },
  {
   "source": [
    "#explanation = cf.explain(testing_features[0].reshape((1,) + testing_features[0].shape))\n",
    "explanation = cf.explain(np.array([1, 0, 60, 50, 0, 0], ndmin=2))"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 13
  },
  {
   "source": [
    "print(explanation['cf'])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'X': array([[ 1.      ,  0.      , 75.774284, 46.530617,  0.      ,  8.349163]],\n      dtype=float32), 'class': 1, 'proba': array([[0.48731952, 0.51268048]]), 'grads_graph': array([[ 3.6182404e-03, -7.1051586e-03,  3.2255707e+01, -7.2528000e+00,\n        -0.0000000e+00,  1.7168257e+01]], dtype=float32), 'grads_num': array([[0., 0., 0., 0., 0., 0.]])}\n"
    }
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 3.      0.     26.     14.4542  1.      1.    ]\n [ 3.      0.     27.      8.6625  0.      0.    ]\n [ 3.      0.     22.      7.225   1.      0.    ]\n ...\n [ 3.      0.     32.      7.8958  0.      0.    ]\n [ 3.      0.     25.      7.7417  2.      0.    ]\n [ 1.      0.     49.     56.9292  1.      1.    ]]\n"
    }
   ],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0.0, 0.0, 0.0], [0.0, 0.0]]\n[[0, 0, 0], [0]]\n"
    },
    {
     "data": {
      "text/plain": "tf.RaggedTensor(values=Tensor(\"RaggedConstant_27/values:0\", shape=(5,), dtype=float32), row_splits=Tensor(\"RaggedConstant_27/RaggedFromRowSplits/row_splits:0\", shape=(3,), dtype=int64))"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars = {0:3, 1:2}\n",
    "#tf.constant([np.zeros(v) for _, v in cat_vars.items()])\n",
    "k = [np.zeros(v) for _, v in cat_vars.items()]\n",
    "print([np.zeros(v).tolist() for _, v in cat_vars.items()])\n",
    "print([[0, 0, 0], [0]])\n",
    "tf.ragged.constant([np.zeros(v).tolist() for _, v in cat_vars.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 2.     0.    51.    12.525  0.     0.   ]]\n"
    }
   ],
   "source": [
    "print(testing_features[0].reshape((1,) + testing_features[0].shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(1, 6)\n"
    }
   ],
   "source": [
    "print(np.array([2, 0, 32, 20.0, 0, 0], ndmin=2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1. 1. 1. 2. 3. 3. 3. 3. 3. 2. 2. 3. 2. 3. 3. 3. 2. 3. 2. 2. 3. 3. 3. 3.\n 3. 3. 3. 3. 1. 3. 3. 3. 2. 1. 3. 3. 3. 2. 3. 1. 2. 3. 1. 3. 3. 2. 2. 3.\n 3. 1. 2. 2. 1. 3. 3. 2. 3. 3. 3. 3. 1. 2. 1. 1. 1. 1. 3. 2. 2. 1. 3. 2.\n 3. 2. 3. 1. 3. 1. 2. 3. 3. 2. 3. 3. 1. 3. 2. 3. 2. 2. 2. 3. 3. 1. 3. 2.\n 1. 1. 3. 2. 3. 3. 2. 3. 3. 3. 1. 1. 3. 1. 1. 3. 3. 3. 1. 3. 2. 1. 2. 3.\n 3. 3. 3. 3. 3. 2. 2. 1. 1. 3. 3. 1. 3. 3. 2. 2. 3. 2. 2. 2. 1. 3. 1. 3.\n 2. 2. 3. 3. 1. 1. 2. 2. 3. 3. 3. 3. 3. 2. 3. 3. 2. 3. 1. 2. 1. 1. 2. 3.\n 1. 3. 1. 3. 1. 2. 3. 3. 3. 2. 1. 3. 3. 3. 1. 3. 1. 2. 1. 1. 2. 3. 3. 1.\n 1. 1. 2. 1. 2. 1. 2. 2. 3. 3. 3. 3. 1. 1. 1. 3. 1. 2. 3. 1. 1. 1. 3. 1.\n 3. 3. 1. 1. 1. 2. 1. 2. 3. 3. 3. 3. 1. 2. 3. 3. 3. 3. 3. 1. 1. 3. 1. 3.\n 1. 3. 3. 3. 1. 2. 1. 1. 3. 1. 3. 1. 2. 2. 3. 2. 1. 3. 3. 3. 3. 3. 1. 1.\n 3. 3. 1. 3. 2. 2. 3. 3. 2. 3. 3. 3. 3. 1. 3. 3. 2. 3. 2. 1. 3. 3. 1. 3.\n 3. 2. 3. 2. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2. 3. 3. 1. 1. 3. 2. 3. 1.\n 2. 3. 2. 3. 3. 1. 1. 1. 2. 3. 1. 1. 3. 1. 1. 3. 3. 3. 2. 3. 3. 2. 2. 3.\n 1. 3. 2. 3. 1. 1. 2. 3. 2. 3. 2. 2. 2. 2. 3. 3. 3. 1. 3. 3. 2. 3. 2. 3.\n 2. 3. 1. 3. 1. 3. 3. 1. 3. 3. 1. 3. 1. 3. 3. 2. 3. 2. 3. 3. 2. 3. 3. 1.\n 3. 1. 2. 3. 3. 3. 2. 3. 3. 1. 3. 3. 2. 1. 1. 3. 3. 1. 2. 3. 1. 1. 3. 3.\n 3. 2. 3. 3. 1. 3. 1. 1. 2. 3. 2. 3. 3. 1. 1. 2. 3. 3. 1. 1. 1. 3. 1. 3.\n 2. 2. 3. 1. 3. 2. 1. 2. 3. 2. 3. 3. 3. 2. 2. 3. 1. 2. 2. 2. 3. 2. 3. 1.\n 3. 1. 3. 2. 2. 3. 1. 3. 1. 2. 3. 1. 3. 3. 3. 2. 3. 3. 3. 1. 2. 3. 3. 3.\n 3. 3. 2. 2. 3. 2. 3. 3. 1. 3. 3. 3. 1. 3. 3. 3. 3. 3. 3. 3. 1. 1. 3. 3.\n 3. 2. 3. 1. 3. 3. 3. 3. 3. 3. 2. 2. 3. 1. 1. 3. 2. 3. 3. 3. 2. 1. 1. 2.\n 3. 3. 1. 2. 2. 2.]\n"
    }
   ],
   "source": [
    "print(training_features[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}